{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw7csAPVvfmR"
   },
   "source": [
    "# 5400 Managing Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba6tBLQLheaw"
   },
   "source": [
    "**Reference**\n",
    "\n",
    "https://www.alphavantage.co/documentation/#*intelligence*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otYXyLWYyiEx"
   },
   "source": [
    "## Access Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHCNjFClxNcn"
   },
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # downloading yahoo finance\n",
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import squarify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import networkx as nx\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "from neo4j import GraphDatabase\n",
    "from datetime import datetime\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mrqfia6ExYMd"
   },
   "source": [
    "Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "YGC3WEXRxSya"
   },
   "outputs": [],
   "source": [
    "# create a complete api with ticker, topics, time period, and our key\n",
    "def getSingleRequest(ticker, topic, time_from, time_to, apikey):\n",
    "  request  = \"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=\" + ticker +  \"&topics=\" + topic + \"&time_from=\" + time_from + \"&time_to=\" + time_to + \"&limit=1000\" + \"&apikey=\" + apikey\n",
    "  return request\n",
    "\n",
    "#  get the data from the api\n",
    "def getData(request):\n",
    "  r = requests.get(request)\n",
    "  data = r.json()\n",
    "  return data\n",
    "\n",
    "# get the top 500 S&P stock name\n",
    "def get_sp500_list():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    tables = pd.read_html(url)\n",
    "    sp500_table = tables[0][\"Symbol\"].tolist()\n",
    "    return sp500_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "ZMaJUgRlHIix"
   },
   "outputs": [],
   "source": [
    "# 500 list\n",
    "ticker = get_sp500_list()\n",
    "\n",
    "# get top 50 list\n",
    "stocks_info = []\n",
    "for symbol in ticker:\n",
    "    stock = yf.Ticker(symbol)\n",
    "    info = stock.info\n",
    "    market_cap = info.get('marketCap', 0)\n",
    "    stocks_info.append((symbol, market_cap))\n",
    "\n",
    "df = pd.DataFrame(stocks_info, columns=['Symbol', 'MarketCap'])\n",
    "\n",
    "df_sorted = df.sort_values(by='MarketCap', ascending=False)\n",
    "\n",
    "top_50_stocks = df_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5MgCg3fNIRxb"
   },
   "outputs": [],
   "source": [
    "# flatten to list\n",
    "top_50_stocks_list = top_50_stocks[\"Symbol\"].tolist()\n",
    "\n",
    "# 15 topics\n",
    "topics = [\n",
    "    \"blockchain\",\n",
    "    \"earnings\",\n",
    "    \"ipo\",\n",
    "    \"mergers_and_acquisitions\",\n",
    "    \"financial_markets\",\n",
    "    \"economy_fiscal\",\n",
    "    \"economy_monetary\",\n",
    "    \"economy_macro\",\n",
    "    \"energy_transportation\",\n",
    "    \"finance\",\n",
    "    \"life_sciences\",\n",
    "    \"manufacturing\",\n",
    "    \"real_estate\",\n",
    "    \"retail_wholesale\",\n",
    "    \"technology\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oyozl49Mh_hu"
   },
   "outputs": [],
   "source": [
    "# This is how a api structure\n",
    "\n",
    "# https://www.alphavantage.co/query?\n",
    "# function=NEWS_SENTIMENT   NO CAHNGE\n",
    "# &tickers=COIN,CRYPTO:BTC,FOREX:USD\n",
    "# &time_from=20220410T0130\n",
    "# &limit=1000               NO CHANGE\n",
    "# &apikey=demo\n",
    "# 150 requrest/min API key: LZQ8M6960ZB021TD\n",
    "\n",
    "\n",
    "# initiate the data\n",
    "file_path = '/content/drive/MyDrive/SPRING24/5400 Managing Data/5400 Project/data.json'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "row_num = len(data)\n",
    "\n",
    "# finished\n",
    "# 20220401 - 20220430\n",
    "# \"20220501T0000\", \"20220531T2359\"\n",
    "# \"20220601T0000\", \"20220630T2359\"\n",
    "# \"20220701T0000\", \"20220731T2359\"\n",
    "# \"20220801T0000\", \"20220831T2359\"\n",
    "# \"20220901T0000\", \"20220930T2359\"\n",
    "# \"20221001T0000\", \"20221031T2359\"\n",
    "# \"20221101T0000\", \"20221130T2359\"\n",
    "# \"20221201T0000\", \"20221231T2359\"\n",
    "# \"20230101T0000\", \"20230131T2359\"\n",
    "# \"20230201T0000\", \"20230228T2359\"\n",
    "# \"20230301T0000\", \"20230331T2359\"\n",
    "# \"20230401T0000\", \"20230430T2359\"\n",
    "# \"20230501T0000\", \"20230531T2359\"\n",
    "# \"20230601T0000\", \"20230630T2359\"\n",
    "# \"20230701T0000\", \"20230731T2359\"\n",
    "# \"20230801T0000\", \"20230831T2359\"\n",
    "# \"20230901T0000\", \"20230930T2359\"\n",
    "# \"20231001T0000\", \"20231031T2359\"\n",
    "# \"20231201T0000\", \"20231231T2359\"\n",
    "# \"20240101T0000\", \"20240131T2359\"\n",
    "# \"20240201T0000\", \"20240229T2359\"\n",
    "# \"20240301T0000\", \"20240331T2359\"\n",
    "\n",
    "# unfinished\n",
    "# \"20220101T0000\", \"20210131T2359\"\n",
    "# \"20220201T0000\", \"20210228T2359\"\n",
    "# \"20220301T0000\", \"20210331T2359\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM66dadzc04o"
   },
   "outputs": [],
   "source": [
    "# current time period\n",
    "period = [\n",
    "[\"20220101T0000\", \"20210131T2359\"],\n",
    "[\"20220201T0000\", \"20210228T2359\"],\n",
    "[\"20220301T0000\", \"20210331T2359\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FGpN78BKGPf"
   },
   "outputs": [],
   "source": [
    "# key = \"LZQ8M6960ZB021TD\"\n",
    "# # access the data with looping\n",
    "# for t1,t2 in period:\n",
    "#   for company in top_50_stocks_list:\n",
    "#       for topic in topics:\n",
    "#           request = getSingleRequest(company, topic,t1, t2, key)\n",
    "#           data_cur = getData(request)\n",
    "\n",
    "#           try:\n",
    "#               row_num += int(data_cur['items'])\n",
    "#               data.extend(data_cur['feed'])\n",
    "#           except KeyError:\n",
    "#               print(f\"Error: 'items' key not found for company {company} and topic{topic} during {t1} and {t2}.\")\n",
    "#               continue  # Skip to the next iteration of the inner loop\n",
    "#           except ValueError:\n",
    "#               print(f\"Error: 'items' key not found for company {company} and topic{topic} during {t1} and {t2}.\")\n",
    "#               continue  # Skip to the next iteration of the inner loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C08nRS1Wdumd",
    "outputId": "f0034bf8-4606-4b1a-c21a-62f5b5bac93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843486\n"
     ]
    }
   ],
   "source": [
    "# print current row number\n",
    "print(row_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeH_iA1HH4u9"
   },
   "outputs": [],
   "source": [
    "# write data\n",
    "# LJQ path\n",
    "file_path = '/content/drive/MyDrive/SPRING24/5400 Managing Data/5400 Project/data.json'\n",
    "\n",
    "\n",
    "# Write data to JSON file in Google Drive\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct4CgM6-ynUo",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LxU5UafLn77"
   },
   "outputs": [],
   "source": [
    "# reorganize dataset\n",
    "def transform_data(data):\n",
    "\n",
    "    transformed_data = []\n",
    "\n",
    "    for item in data:\n",
    "        authors_dict = {author: True for author in item['authors']}\n",
    "        topics_dict = {topic['topic']: float(topic['relevance_score']) for topic in item['topics']}\n",
    "        ticker_sentiment_dict = {\n",
    "            ticker['ticker']: {\n",
    "                'relevance_score': float(ticker['relevance_score']),\n",
    "                'ticker_sentiment_score': float(ticker['ticker_sentiment_score']),\n",
    "                'ticker_sentiment_label': ticker['ticker_sentiment_label']\n",
    "            } for ticker in item['ticker_sentiment']\n",
    "        }\n",
    "\n",
    "        transformed_item = item.copy()\n",
    "        transformed_item['authors'] = authors_dict\n",
    "        transformed_item['topics'] = topics_dict\n",
    "        transformed_item['ticker_sentiment'] = ticker_sentiment_dict\n",
    "\n",
    "        transformed_data.append(transformed_item)\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "def export_json_data(data, file_path):\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "# Transform the data\n",
    "transformed_data = transform_data(data)\n",
    "\n",
    "# Export the transformed data to a new JSON file\n",
    "export_json_data(transformed_data, '/content/drive/MyDrive/SPRING24/5400 Managing Data/5400 Project/5400.FP.json')\n",
    "\n",
    "print(\"Transformation complete and data exported to '5400.FP.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0kCmz5TM4wI"
   },
   "outputs": [],
   "source": [
    "file_path = '/content/drive/MyDrive/SPRING24/5400 Managing Data/5400 Project/5400.FP.json'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    tfdata = json.load(json_file)\n",
    "\n",
    "row_num = len(tfdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKApoLbFyp7j"
   },
   "source": [
    "## Buiding up MongoDB Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anjxx4YGAtNE",
    "outputId": "b5e8c1a7-71a2-4cea-8185-92f73671ed9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
      "Requirement already satisfied: dnspython in /usr/local/lib/python3.10/dist-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymongo\n",
    "# !pip install dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "id": "dIkPFoooy3OK"
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client.apan5400\n",
    "collection = db['Aricles']\n",
    "\n",
    "with open('./Articles.json', 'r') as file:\n",
    "    Articles = json.load(file)\n",
    "\n",
    "_ = collection.insert_many(Articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted\n"
     ]
    }
   ],
   "source": [
    "collection.delete_many({})\n",
    "print(\"deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_dpnPp9yzMo"
   },
   "source": [
    "## MongoDB Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "id": "xXg610jGCrlR"
   },
   "outputs": [],
   "source": [
    "def select_ticker(ticker):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$match\": {\n",
    "                f\"ticker_sentiment.{ticker}\": {\"$exists\": True}  # Check if the specified ticker exists\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"relevant_relevance_score\": f\"$ticker_sentiment.{ticker}.relevance_score\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sort\": {\n",
    "                \"relevant_relevance_score\": -1            }\n",
    "        },\n",
    "        {\n",
    "            \"$limit\": 1\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = list(collection.aggregate(pipeline))\n",
    "\n",
    "    if results:\n",
    "        return(results[0])  # Print the first (and only) result\n",
    "    else:\n",
    "        return(None)  # Print None if there are no results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ticker_by_topic(ticker,topic):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$match\": {\n",
    "                f\"topics.{topic}\": {\"$exists\": True},  # Check if the specified topic exists\n",
    "                f\"ticker_sentiment.{ticker}\": {\"$exists\": True}  # Check if the specified ticker exists\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"topic_relevance\": f\"$topics.{topic}\",  # Extract relevant topic relevance data\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sort\": {\n",
    "                \"topic_relevance\": -1  # Sort by topic relevance first\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$limit\": 1  # Limit to the article with the highest ticker relevance score from the previously selected articles\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = list(collection.aggregate(pipeline))\n",
    "\n",
    "    if results:\n",
    "        return(results[0])  # Print the first (and only) result\n",
    "    else:\n",
    "        return(None)  # Print None if there are no results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettreemap(article):\n",
    "    if not article:\n",
    "        return None\n",
    "        \n",
    "    # Normalize scores for gradient calculation\n",
    "    scores = [article['ticker_sentiment_score'] for article in data['ticker_sentiment'].values()]\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "\n",
    "    def get_color(score, label):\n",
    "        # Define the gradient - neutral grey, bullish green, bearish red\n",
    "        if 'Neutral' in label:\n",
    "            return '#e1e1e1'\n",
    "        elif 'Bullish' in label:\n",
    "            # Green gradient from light to dark based on score\n",
    "            green_cmap = plt.get_cmap('YlGn')\n",
    "            return green_cmap(np.interp(score, [0, max_score], [0.1, 0.5]))  # Adjust [0.3, 1.0] for your gradient range\n",
    "        elif 'Bearish' in label:\n",
    "            # Red gradient from light to dark based on score\n",
    "            red_cmap = plt.get_cmap('YlOrRd')\n",
    "            return red_cmap(np.interp(score, [min_score, 0], [0.1, 0.5]))  # Adjust [1.0, 0.3] for your gradient range\n",
    "    \n",
    "    companies = list(article['ticker_sentiment'].keys())\n",
    "    relevance_scores = [article['ticker_sentiment'][company]['relevance_score'] for company in companies]\n",
    "    sentiment_scores = [article['ticker_sentiment'][company]['ticker_sentiment_score'] for company in companies]\n",
    "    labels = [f\"{company}\\nScore: {article['ticker_sentiment'][company]['ticker_sentiment_score']:.3f}\\n{article['ticker_sentiment'][company]['ticker_sentiment_label']}\"\n",
    "              for company in companies]\n",
    "    colors = [get_color(article['ticker_sentiment'][company]['ticker_sentiment_score'],\n",
    "                        article['ticker_sentiment'][company]['ticker_sentiment_label']) for company in companies]\n",
    "    \n",
    "    bullish_color = \"#31655f\"\n",
    "    bearish_color = \"#652c32\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a treemap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    squarify.plot(sizes=relevance_scores, label=labels, color=colors, alpha=0.8, pad=True)\n",
    "    plt.title('Company Ticker Sentiment Treemap')\n",
    "    plt.axis('off')  # Hide the axes\n",
    "\n",
    "    return plt  # Return bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Ensure 'data' variable is defined in your context\n",
    "def get_chart(article):\n",
    "    if not article:\n",
    "        return None\n",
    "\n",
    "    current_value = article['overall_sentiment_score']\n",
    "    \n",
    "    # Set the plot's and paper's background color to transparent\n",
    "    plot_bgcolor = \"rgba(0,0,0,0)\"\n",
    "    quadrant_colors = [plot_bgcolor, \"#2bad4e\", \"#85e043\", \"#eff229\", \"#f2a529\", \"#f25829\"]\n",
    "    quadrant_text = [\"\", \"<b>Bullish</b>\", \"<b>Somewhat-Bullish</b>\", \"<b>Neutral</b>\", \"<b>Somewhat-Bearish</b>\", \"<b>Bearish</b>\"]\n",
    "    n_quadrants = len(quadrant_colors) - 1\n",
    "    \n",
    "    min_value = -1\n",
    "    max_value = 1\n",
    "    hand_length = np.sqrt(2) / 4\n",
    "    hand_angle = np.pi * (1 - (max(min_value, min(max_value, current_value)) - min_value) / (max_value - min_value))\n",
    "    \n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Pie(\n",
    "                values=[0.5] + (np.ones(n_quadrants) / 2 / n_quadrants).tolist(),\n",
    "                rotation=90,\n",
    "                hole=0.5,\n",
    "                marker_colors=quadrant_colors,\n",
    "                text=quadrant_text,\n",
    "                textinfo=\"text\",\n",
    "                hoverinfo=\"skip\",\n",
    "            ),\n",
    "        ],\n",
    "        layout=go.Layout(\n",
    "            showlegend=False,\n",
    "            margin=dict(b=0, t=10, l=10, r=10),\n",
    "            width=450,\n",
    "            height=450,\n",
    "            paper_bgcolor=\"rgba(0,0,0,0)\",  # Set paper background to transparent\n",
    "            plot_bgcolor=\"rgba(0,0,0,0)\",  # Ensure plot background is also transparent\n",
    "            annotations=[\n",
    "                go.layout.Annotation(\n",
    "                    text=f\"<b>Overall Sentiment Score:</b><br>{current_value:.2f}\",\n",
    "                    x=0.5, xanchor=\"center\", xref=\"paper\",\n",
    "                    y=0.25, yanchor=\"bottom\", yref=\"paper\",\n",
    "                    showarrow=False,\n",
    "                )\n",
    "            ],\n",
    "            shapes=[\n",
    "                go.layout.Shape(\n",
    "                    type=\"circle\",\n",
    "                    x0=0.48, x1=0.52,\n",
    "                    y0=0.48, y1=0.52,\n",
    "                    fillcolor=\"#333\",\n",
    "                    line_color=\"#333\",\n",
    "                ),\n",
    "                go.layout.Shape(\n",
    "                    type=\"line\",\n",
    "                    x0=0.5, x1=0.5 + hand_length * np.cos(hand_angle),\n",
    "                    y0=0.5, y1=0.5 + hand_length * np.sin(hand_angle),\n",
    "                    line=dict(color=\"#333\", width=4)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    return fig.to_html(full_html=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_map(article):\n",
    "    if not article:\n",
    "        return None\n",
    "    # enviroment \n",
    "    database_name = \"neo4j\"\n",
    "    username = \"neo4j\"\n",
    "    password = \"apan5400\"\n",
    "    uri = \"bolt://localhost:7687/\" + database_name\n",
    "    \n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    session = driver.session()\n",
    "    \n",
    "    # delete all the relationship just in case \n",
    "    querydelete = (\"MATCH (n) OPTIONAL MATCH (n)-[r]-() DELETE n,r\")\n",
    "    _ = session.run(querydelete)\n",
    "    \n",
    "    # write data locally\n",
    "    with open('data.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    \n",
    "    # upload the data to neo4j\n",
    "    !docker cp \"./data.json\" apan5400:/var/lib/neo4j/import/data.json\n",
    "    \n",
    "    # create relationship\n",
    "    query = \"\"\"\n",
    "        CALL apoc.load.json(\"file:///data.json\") YIELD value\n",
    "        CREATE (article:Article {\n",
    "            id: value._id,\n",
    "            title: value.title,\n",
    "            overall_sentiment_score: value.overall_sentiment_score,\n",
    "            overall_sentiment_label: value.overall_sentiment_label\n",
    "        })\n",
    "        FOREACH (tickerName IN keys(value.ticker_sentiment) |\n",
    "            MERGE (ticker:Ticker {name: tickerName})\n",
    "            ON CREATE SET ticker.relevance_score = value.ticker_sentiment[tickerName].relevance_score,\n",
    "                           ticker.ticker_sentiment_score = value.ticker_sentiment[tickerName].ticker_sentiment_score,\n",
    "                           ticker.ticker_sentiment_label = value.ticker_sentiment[tickerName].ticker_sentiment_label\n",
    "            CREATE (ticker)-[:MENTIONED_IN]->(article)\n",
    "        )\n",
    "        FOREACH (topicName IN keys(value.topics) |\n",
    "            MERGE (topic:Topic {name: topicName})\n",
    "            ON CREATE SET topic.relevance_score = value.topics[topicName]\n",
    "            CREATE (topic)-[:DISCUSSED_IN]->(article)\n",
    "        )\n",
    "        \"\"\"\n",
    "    _ = session.run(query)\n",
    "    \n",
    "    \n",
    "    graph = Graph(uri, auth=(username, password))\n",
    "    \n",
    "    # Initialize the graph\n",
    "    G = nx.MultiDiGraph()\n",
    "    positions = {}\n",
    "    \n",
    "    # Central article node (layer 0)\n",
    "    G.add_node(\"Article\", label=\"Current\\nArticle\", layer=0)\n",
    "    positions[\"Article\"] = (0, 0)\n",
    "    \n",
    "    # Fetch topics and tickers from the Neo4j database\n",
    "    topic_nodes = session.run(\"MATCH (n:Topic) RETURN n as topic\")\n",
    "    topics = [record[\"topic\"] for record in topic_nodes]\n",
    "    ticker_nodes = session.run(\"MATCH (n:Ticker) RETURN n as ticker\")\n",
    "    tickers = [record[\"ticker\"] for record in ticker_nodes]\n",
    "    \n",
    "    # Nodes for counts of topics and tickers (layer 1)\n",
    "    G.add_node(\"Topics\", label=f\"Relative\\n{len(topics)} Topics\", layer=1)\n",
    "    G.add_node(\"Tickers\", label=f\"Relative\\n{len(tickers)} Tickers\", layer=1)\n",
    "    positions[\"Topics\"] = (1, 0)\n",
    "    positions[\"Tickers\"] = (-1, 0)\n",
    "    \n",
    "    G.add_edge(\"Article\", \"Topics\")\n",
    "    G.add_edge(\"Article\", \"Tickers\")\n",
    "    \n",
    "    # Arrange nodes in a half-fan formation around the central nodes\n",
    "    # Increasing the radius by 1.5 times\n",
    "    radius = 1.5 * 1.5\n",
    "    angle_step = 180 / max(len(topics), len(tickers))\n",
    "    \n",
    "    for i, topic in enumerate(topics):\n",
    "        angle = 90 - (i * angle_step)  # Start from vertical top and spread downwards\n",
    "        x = 1 + radius * np.cos(np.radians(angle))\n",
    "        y = radius * np.sin(np.radians(angle))\n",
    "        topic_label = f\"{topic['name']}\\nRelevance: {topic['relevance_score']:.2f}\"\n",
    "        G.add_node(topic_label, label=topic_label, layer=2)\n",
    "        positions[topic_label] = (x, y)\n",
    "        G.add_edge(\"Topics\", topic_label)\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        angle = 90 - (i * angle_step)  # Start from vertical top and spread downwards\n",
    "        x = -1 - radius * np.cos(np.radians(angle))\n",
    "        y = radius * np.sin(np.radians(angle))\n",
    "        ticker_label = f\"{ticker['name']}\\n Relevance: {ticker['relevance_score']:.2f}\\nSentiment: {ticker['ticker_sentiment_label']}\"\n",
    "        G.add_node(ticker_label, label=ticker_label, layer=2)\n",
    "        positions[ticker_label] = (x, y)\n",
    "        G.add_edge(\"Tickers\", ticker_label)\n",
    "    \n",
    "    # Draw the graph with custom positions\n",
    "    plt.figure(figsize=(15, 10))  # Increase figure size for better clarity and spread\n",
    "    nx.draw(G, positions, with_labels=True, labels={node: G.nodes[node]['label'] for node in G.nodes},\n",
    "            node_color='lightblue', node_size=8000, font_size=12, font_weight='bold', arrowstyle='-|>', arrowsize=15)\n",
    "    plt.title('Article Structure with Topic and Ticker Distribution')\n",
    "    plt.axis('off')  # Turn off the axis\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    topics = [\n",
    "        \"Blockchain\", \"Earnings\", \"IPO\", \"Mergers & Acquisitions\",\n",
    "        \"Financial Markets\", \"Economy - Fiscal Policy\", \"Economy - Monetary Policy\",\n",
    "        \"Economy - Macro/Overall\", \"Energy & Transportation\", \"Finance\",\n",
    "        \"Life Sciences\", \"Manufacturing\", \"Real Estate & Construction\", \"Retail & Wholesale\",\n",
    "        \"Technology\"\n",
    "    ]\n",
    "    tickers = ['MSFT', 'AAPL', 'NVDA', 'GOOGL', 'GOOG', 'AMZN', 'META', 'LLY', 'AVGO', 'V', 'JPM', 'TSLA', 'WMT', 'XOM',\n",
    "               'MA', 'UNH', 'PG', 'JNJ', 'HD', 'ORCL', 'MRK', 'COST', 'CVX', 'ABBV', 'BAC', 'CRM', 'NFLX', 'AMD', 'KO', 'PEP',\n",
    "               'LIN', 'TMO', 'ADBE', 'DIS', 'WFC', 'ACN', 'CSCO', 'MCD', 'TMUS', 'QCOM', 'ABT', 'CAT', 'DHR', 'INTU', 'AMAT',\n",
    "               'VZ', 'GE', 'IBM', 'AXP', 'CMCSA']\n",
    "    \n",
    "    selected_ticker = None\n",
    "    selected_topic = None\n",
    "    error_message = None\n",
    "\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        selected_ticker = request.form.get('ticker')\n",
    "        selected_topic = request.form.get('topic')\n",
    "\n",
    "        article = select_ticker_by_topic(selected_ticker, selected_topic) if selected_topic else select_ticker(selected_ticker)\n",
    "\n",
    "        if article:\n",
    "            sentiment_chart_html = get_chart(article)  # Assuming this returns HTML\n",
    "            \n",
    "            # generate treemap\n",
    "            treemap_fig = gettreemap(article)\n",
    "            treemap_img = io.BytesIO()\n",
    "            treemap_fig.savefig(treemap_img, format='png', bbox_inches='tight')\n",
    "            treemap_img.seek(0)\n",
    "            treemap_plot_url = base64.b64encode(treemap_img.getvalue()).decode('utf8')\n",
    "\n",
    "            # Generate relation map graph\n",
    "            relation_map_fig = get_relation_map(article)\n",
    "            relation_map_img = io.BytesIO()\n",
    "            relation_map_fig.savefig(relation_map_img, format='png', bbox_inches='tight')\n",
    "            relation_map_img.seek(0)\n",
    "            relation_map_plot_url = base64.b64encode(relation_map_img.getvalue()).decode('utf8')\n",
    "            \n",
    "\n",
    "            authors = ', '.join([key for key, value in article['authors'].items() if value])\n",
    "            publication_time = datetime.strptime(article['time_published'], '%Y%m%dT%H%M%S').strftime('%Y %b %d %H:%M:%S')\n",
    "\n",
    "\n",
    "            return render_template('index.html', topics=topics, tickers=tickers,\n",
    "                                   selected_ticker=selected_ticker, \n",
    "                                   selected_topic=selected_topic,\n",
    "                                   treemap_plot_url=treemap_plot_url, \n",
    "                                   relation_map_plot_url=relation_map_plot_url,\n",
    "                                   sentiment_chart_html=sentiment_chart_html,\n",
    "                                   article_title=article['title'], article_url=article['url'],\n",
    "                                   authors=authors, summary=article['summary'],\n",
    "                                   publication_time=publication_time)\n",
    "        else:\n",
    "            error_message = f\"Sorry, we don't have articles relative to {selected_ticker}\" + (f\" and {selected_topic}\" if selected_topic else \"\") + \".\"\n",
    "            return render_template('index.html', topics=topics, tickers=tickers, selected_ticker=selected_ticker, \n",
    "                                   selected_topic=selected_topic, error_message=error_message)\n",
    "    else:\n",
    "        return render_template('index.html', topics=topics, tickers=tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:19] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:19] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:19] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:19] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:19] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying to container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 4.61kB to apan5400:/var/lib/neo4j/import/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Apr/2024 23:00:26] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:26] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:26] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:26] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:00:26] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:45] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:45] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:45] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:45] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:45] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying to container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 4.61kB to apan5400:/var/lib/neo4j/import/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Apr/2024 23:03:55] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:55] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:55] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:55] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:03:55] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying to container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 4.61kB to apan5400:/var/lib/neo4j/import/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Apr/2024 23:05:40] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:05:40] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:05:40] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:05:40] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:05:40] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying to container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 4.61kB to apan5400:/var/lib/neo4j/import/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Apr/2024 23:07:22] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:07:22] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:07:22] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:07:22] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:07:22] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying to container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 4.61kB to apan5400:/var/lib/neo4j/import/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Apr/2024 23:08:14] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:08:14] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:08:14] \"GET /static/images/alpha_vantage.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:08:14] \"GET /static/images/blue_marble.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [17/Apr/2024 23:08:14] \"GET /static/images/white_marble.jpeg HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
